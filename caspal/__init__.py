#!/usr/bin/env python

import operator
from enum import Enum


class TokenType(Enum):
    NUMBER = 1
    PLUS = 2
    MINUS = 3
    MULT = 4
    DIV = 5
    EOF = 6


class Token(object):
    """Represents a lexer token"""

    def __init__(self, type, value):
        if not isinstance(type, TokenType):
            raise TypeError('Invalid token type')

        self.type, self.value = type, value

    def __eq__(self, other):
        return self.type == other.type and \
            self.value == other.value

    def __repr__(self):
        return 'Token({}, {})'.format(self.value, self.type)


class Lexer(object):
    """The lexer for Caspal.

    Gets a stream of characters and converts them into tokens that are then
    sent to the parser.

    """

    def __init__(self, text):
        self.text = text
        self.pos = 0
        self.current_char = self.text[self.pos]

    def advance(self):
        self.pos += 1
        if self.pos > len(self.text) - 1:
            self.current_char = None
        else:
            self.current_char = self.text[self.pos]

    def ignore_whitespace(self):
        """Ignores whitespace character from stream"""
        while self.current_char is not None and self.current_char == ' ':
            self.advance()

    def get_next_token(self):
        ch = self.current_char

        if ch is None:
            return Token(TokenType.EOF, None)

        if ch.isspace():
            self.ignore_whitespace()
            ch = self.current_char

        if ch.isdigit():
            self.advance()
            return Token(TokenType.NUMBER, ch)

        if ch == '+':
            self.advance()
            return Token(TokenType.PLUS, ch)

        if ch == '-':
            self.advance()
            return Token(TokenType.MINUS, ch)

        if ch == '*':
            self.advance()
            return Token(TokenType.MULT, ch)

        if ch == '/':
            self.advance()
            return Token(TokenType.DIV, ch)

        raise Exception('Invalid char: {}'.format(ch))

    def get_all_tokens(self):
        """Fetches all tokens from a stream, at once."""
        tokens = []
        token = self.get_next_token()
        while token is not None and token.type != TokenType.EOF:
            tokens.append(token)
            token = self.get_next_token()

        return tokens


def display_tokens(lexer):
    tokens = []
    token = lexer.get_next_token()
    while token.value is not None:
        tokens.append(token)
        token = lexer.get_next_token()

    print("TOKENS: {}".format(tokens))


class Parser(object):
    """Parser for Caspal.

    Parses a token generated by the Lexer and converts it into
    an AST(Abstract Syntax Tree).

    """

    def __init__(self, lexer):
        self.lexer = lexer
        self.current_token = self.lexer.get_next_token()

    def advance(self):
        self.current_token = self.lexer.get_next_token()

    def number(self):
        """Parses a number

        Note: Can only parse an integer for now.
        """
        res = ''
        token = self.current_token

        while token is not None and token.type == TokenType.NUMBER:
            res = res + token.value
            self.advance()
            token = self.current_token

        return int(res)

    def term(self):
        return self.number()

    def factor(self):
        res = self.term()
        op = self.current_token

        while op.type in (TokenType.MULT, TokenType.DIV):
            self.advance()
            res1 = self.term()

            if op.type == TokenType.MULT:
                res = res * res1
            elif op.type == TokenType.DIV:
                res = int(res / res1)

            op = self.current_token

        return res

    def expression(self):
        """Parses an arithmetic expression"""
        res = self.factor()
        op = self.current_token

        while op.type in (TokenType.PLUS, TokenType.MINUS):
            self.advance()
            res1 = self.factor()

            if op.type == TokenType.PLUS:
                res = res + res1
            elif op.type == TokenType.MINUS:
                res = res - res1

            op = self.current_token

        return res

    def parse(self):
        return self.expression()
